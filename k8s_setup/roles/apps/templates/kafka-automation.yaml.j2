---
# ------------------------------------------------------------------------
# Pod 1: kafka-cli (just a shell with Kafka+GCP dependencies)
# ------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: kafka-cli
  labels:
    app: kafka-cli
spec:
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""  # Use control-plane label for master
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
      effect: "NoSchedule"
  containers:
    - name: kafka-cli-container
      image: python:3.9-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          apt-get update && apt-get install -y gcc libatlas-base-dev &&
          pip install --no-cache-dir kafka-python google-cloud-storage matplotlib pillow &&
          tail -f /dev/null
  restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: kafka-cli-svc
spec:
  selector:
    app: kafka-cli
  ports:
    - name: kafka-cli-port
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 30080
  type: NodePort

---
# ------------------------------------------------------------------------
# Pod 2: kafka-producer (runs the producer code automatically)
# ------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: kafka-producer
  labels:
    app: kafka-producer
spec:
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
      effect: "NoSchedule"
  containers:
    - name: kafka-producer-container
      image: python:3.9-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          apt-get update && apt-get install -y gcc libatlas-base-dev &&
          pip install --no-cache-dir kafka-python google-cloud-storage matplotlib pillow &&
          mkdir -p /app && cd /app &&
          cp /scripts/simulation_parameters.py . &&
          cp /scripts/kafka_producer.py . &&
          echo "Running producer..." &&
          python kafka_producer.py &&
          echo "Producer done. Keeping container alive." &&
          tail -f /dev/null
      volumeMounts:
        - name: scripts-volume
          mountPath: /scripts
          readOnly: true
  volumes:
    - name: scripts-volume
      hostPath:
        path: /home/asmae/kafka-scripts
  restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: kafka-producer-svc
spec:
  selector:
    app: kafka-producer
  ports:
    - name: kafka-producer-port
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 30081
  type: NodePort

---
# ------------------------------------------------------------------------
# Pod 3: kafka-listener-1 (runs the consumer)
# ------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: kafka-listener-1
  labels:
    app: kafka-listener-1
spec:
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
      effect: "NoSchedule"
  containers:
    - name: kafka-listener-1-container
      image: python:3.9-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          apt-get update && apt-get install -y gcc libatlas-base-dev &&
          pip install --no-cache-dir kafka-python google-cloud-storage matplotlib pillow &&
          mkdir -p /app && cd /app &&
          cp /scripts/simulation_parameters.py . &&
          cp /scripts/kafka_consumer.py . &&
          echo "Running consumer #1..." &&
          python kafka_consumer.py &&
          echo "Consumer #1 done. Keeping container alive." &&
          tail -f /dev/null
      volumeMounts:
        - name: scripts-volume
          mountPath: /scripts
          readOnly: true
  volumes:
    - name: scripts-volume
      hostPath:
        path: /home/asmae/kafka-scripts
  restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: kafka-listener-1-svc
spec:
  selector:
    app: kafka-listener-1
  ports:
    - name: listener1-port
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 30082
  type: NodePort

---
# ------------------------------------------------------------------------
# Pod 4: kafka-listener-2 (runs the consumer again, or a second instance)
# ------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: kafka-listener-2
  labels:
    app: kafka-listener-2
spec:
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
      effect: "NoSchedule"
  containers:
    - name: kafka-listener-2-container
      image: python:3.9-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          apt-get update && apt-get install -y gcc libatlas-base-dev &&
          pip install --no-cache-dir kafka-python google-cloud-storage matplotlib pillow &&
          mkdir -p /app && cd /app &&
          cp /scripts/simulation_parameters.py . &&
          cp /scripts/kafka_consumer.py . &&
          echo "Running consumer #2..." &&
          python kafka_consumer.py &&
          echo "Consumer #2 done. Keeping container alive." &&
          tail -f /dev/null
      volumeMounts:
        - name: scripts-volume
          mountPath: /scripts
          readOnly: true
  volumes:
    - name: scripts-volume
      hostPath:
        path: /home/asmae/kafka-scripts
  restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: kafka-listener-2-svc
spec:
  selector:
    app: kafka-listener-2
  ports:
    - name: listener2-port
      protocol: TCP
      port: 8080
      targetPort: 8080
      nodePort: 30083
  type: NodePort